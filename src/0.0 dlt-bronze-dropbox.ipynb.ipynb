{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b4f797-f0aa-4b27-ade6-f648f1276bbc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DLT Bronze Autoloader Ingestion - Dropbox\n",
    "***\n",
    "\n",
    "This notebook automatically streams in any files that have been landed in the configured volume as a full text key value pair brone quality table with the following schema:  \n",
    "\n",
    "* **fullFilePath** \n",
    "* **datasource**\n",
    "* **inputFileName**\n",
    "* **ingestTime**\n",
    "* **ingestDate**\n",
    "* **value**\n",
    "* **fileMetadata**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b09e14c5-6d03-48c3-892f-a48d07d63a4f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*** \n",
    "\n",
    "Import dlt and the operations and classes defined for the pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a5908f0-5020-4b8c-a9c0-016f744a2102",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "256f2a61-96b7-456a-8f2e-3305a37d341c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from classDefinitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb03d314-f789-411a-bc77-32ec063b8703",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***\n",
    "\n",
    "For development purposes only, uncommment the below code to manually set the Spark Conf Variables using Databricks Widgets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "720766bb-1aae-46e9-90f6-574f3aad79a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # used for active development, but not run during DLT execution, use DLT configurations instead\n",
    "# dbutils.widgets.dropdown(name = \"env_mode\", defaultValue = \"prd\", choices = [\"dev\", \"tst\", \"uat\", \"prd\"], label = \"Environment Mode\")\n",
    "# dbutils.widgets.text(name = \"catalog_name\", defaultValue=\"\", label=\"Catalog Name\")\n",
    "# dbutils.widgets.text(name = \"schema_name\", defaultValue=\"synthea\", label=\"Schema Name\")\n",
    "# dbutils.widgets.text(name = \"volume_name\", defaultValue=\"synthetic_files_raw\", label=\"Volume Name\")\n",
    "\n",
    "# spark.conf.set(\"workflow_inputs.env_mode\", dbutils.widgets.get(name = \"env_mode\"))\n",
    "# spark.conf.set(\"workflow_inputs.catalog_name\", dbutils.widgets.get(name = \"catalog_name\"))\n",
    "# spark.conf.set(\"workflow_inputs.schema_name\", dbutils.widgets.get(name = \"schema_name\"))\n",
    "# spark.conf.set(\"workflow_inputs.volume_name\", dbutils.widgets.get(name = \"volume_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b60e1055-e1fd-4405-aeaa-98ce96e9197f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.widgets.removeAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17a2fa59-35a4-4f17-b8ce-cb1eaf7e41cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***\n",
    "\n",
    "Retreive inputs for the DLT run from the Spark Conf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74e22f05-9a9a-4b9c-828f-dd015e8b1876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env_mode = spark.conf.get(\"workflow_inputs.env_mode\")\n",
    "catalog_name = spark.conf.get(\"workflow_inputs.catalog_name\")\n",
    "schema_name = spark.conf.get(\"workflow_inputs.schema_name\")\n",
    "volume_name = spark.conf.get(\"workflow_inputs.volume_name\")\n",
    "volume_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/\"\n",
    "print(f\"\"\"\n",
    "    env_mode = {env_mode}\n",
    "    catalog_name = {catalog_name}\n",
    "    schema_name = {schema_name}\n",
    "    volume_name = {volume_name}\n",
    "    volume_path = {volume_path}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fe391c1-baa8-45b6-8e84-6687bf39a0cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***\n",
    "\n",
    "Initialize the pipeline as an IngestionDLT class object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cafce1f0-a74a-4fb0-a4d2-e12b97f09771",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Pipeline = IngestionDLT(\n",
    "    spark = spark\n",
    "    ,env_mode = env_mode\n",
    "    ,catalog = catalog_name\n",
    "    ,schema = schema_name\n",
    "    ,volume = volume_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a611cbe-714c-4c58-a1f0-87c3b73d74b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8fc0c00-f2e1-4581-a857-70f57184bd56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***\n",
    "\n",
    "Ingest the raw files into a key-value pair bronze table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d64e8512-6031-41e8-b7c0-f7663fc476cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Pipeline.ingest_raw_to_bronze(\n",
    "    table_name=\"synthea_csv_bronze\"\n",
    "    ,table_comment=\"A full text record of every file that has landed in our raw synthea landing folder.\"\n",
    "    ,table_properties={\"quality\":\"bronze\", \"phi\":\"True\", \"pii\":\"True\", \"pci\":\"False\"}\n",
    "    ,source_folder_path_from_volume=\"output/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c89d402e-a1c3-49c1-9474-fa35dde08fc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Pipeline.list_dropbox_files(\n",
    "  bronze_table = \"synthea_csv_bronze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0fa4182-fe22-4056-b374-4fd85dc53b34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filenames = spark.sql(f\"select distinct * from {catalog_name}.{schema_name}.temp_landed_bronze_files\").collect()\n",
    "# filenames_list = [row.inputFileName for row in filenames]\n",
    "# filenames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2af7ed7-3552-4160-8239-2e005d7d0de3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filenames_list = (\"encounters.csv\", \"allergies.csv\", \"imaging_studies.csv\", \"providers.csv\", \"medications.csv\", \"patients.csv\", \"immunizations.csv\", \"payer_transitions.csv\", \"conditions.csv\", \"observations.csv\", \"claims_transactions.csv\", \"careplans.csv\", \"supplies.csv\", \"procedures.csv\", \"devices.csv\", \"payers.csv\", \"claims.csv\", \"organizations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c72c268b-04f1-4b26-8150-41e03c7c4da0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for filename in filenames_list:\n",
    "  name = filename.replace(\".\", \"_\")\n",
    "  Pipeline.split_bronze_table(bronze_table = \"synthea_csv_bronze\", filename = filename, table_name = name, live = True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "0.0 dlt-bronze-dropbox.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
